{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suburban-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_curve\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lasting-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18750 images belonging to 2 classes.\n",
      "Found 6250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH= 'training'\n",
    "TEST_PATH= 'testing'\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, featurewise_center=True)\n",
    "\n",
    "datagen.mean = [123.68, 116.779, 103.939]\n",
    "\n",
    "train_gen = datagen.flow_from_directory(TRAIN_PATH, class_mode='binary', \n",
    "                                      batch_size=64, target_size=(224,224))\n",
    "test_gen = datagen.flow_from_directory(TEST_PATH, class_mode='binary', \n",
    "                                      batch_size=64, target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifty-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform',\n",
    "                    padding='same', input_shape=(224,224,3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    opt=SGD(lr=0.01, momentum=0.9)\n",
    "    \n",
    "    model.compile(optimizer=opt, metrics=['acc',f1_m,precision_m, recall_m], loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-quest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basma.elsaify/.pyenv/versions/3.8.3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 203s 689ms/step - loss: 1.2323 - acc: 0.5812 - f1_m: 0.5380 - precision_m: 0.5956 - recall_m: 0.5920 - val_loss: 0.5876 - val_acc: 0.6822 - val_f1_m: 0.6339 - val_precision_m: 0.7454 - val_recall_m: 0.5578\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n",
    "                              min_delta=1E-7)\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=len(train_gen), callbacks=[rlrop],\n",
    "         epochs=10, validation_data=test_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "searching-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7494252324104309],\n",
       " 'acc': [0.6262933611869812],\n",
       " 'f1_m': [0.593091607093811],\n",
       " 'precision_m': [0.6603574752807617],\n",
       " 'recall_m': [0.6043522953987122],\n",
       " 'val_loss': [0.5875988006591797],\n",
       " 'val_acc': [0.6822400093078613],\n",
       " 'val_f1_m': [0.6338533759117126],\n",
       " 'val_precision_m': [0.7453943490982056],\n",
       " 'val_recall_m': [0.5577754378318787],\n",
       " 'lr': [0.01]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "moral-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['acc'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_acc'], color='orange', label='test')\n",
    "    plt.show()\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "clinical-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5875987410545349, 0.6822400093078613, 0.633675754070282, 0.7449535727500916, 0.5574128031730652]\n"
     ]
    }
   ],
   "source": [
    "evaluated = model.evaluate_generator(test_gen,  steps=len(test_gen), verbose=1)\n",
    "print(evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "religious-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    flat = Flatten()(model.layers[-1].output)\n",
    "    dense1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat)\n",
    "    output = Dense(1, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    \n",
    "    # Learning rate has been reduced to 0.001 as the model is already trained\n",
    "    opt=SGD(lr=0.001, momentum=0.9)\n",
    "    \n",
    "    model.compile(optimizer=opt, metrics=['acc',f1_m,precision_m, recall_m], loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "polyphonic-phase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1704s 6s/step - loss: 1.0476 - accuracy: 0.9291 - val_loss: 0.0709 - val_accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=len(train_gen), epochs=10, \n",
    "                              validation_data=test_gen, validation_steps=len(test_gen), \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "regular-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "peaceful-poetry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 403s 4s/step - loss: 0.0709 - accuracy: 0.9723\n",
      "[0.07094848155975342, 0.972320020198822]\n"
     ]
    }
   ],
   "source": [
    "evaluated = model.evaluate_generator(test_gen,  steps=len(test_gen), verbose=1)\n",
    "print(evaluated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
